{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE = \"mnist/swin\"\n",
    "print(f\"Active {TITLE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "import models\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms\n",
    "from timm.optim import create_optimizer\n",
    "from timm.utils import accuracy, AverageMeter\n",
    "from datasets.mnist.mnist_data import get_mnist_dataset\n",
    "from util.show_images import ShowImages\n",
    "from util.visualization import Visualization\n",
    "from util.notification import Notification\n",
    "from util.custom_time import Time\n",
    "from util.path_functions import PathFunctions\n",
    "\n",
    "path_functions_instance = PathFunctions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEFILENAME = \"mnist-swin\"\n",
    "SAVEWEIGHTPATH = f\"dev/result/weight/{SAVEFILENAME}.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args_parser():\n",
    "  parser = argparse.ArgumentParser(description=\"Training Config\")\n",
    "  parser.add_argument('--batch-size', default=64, type=int)\n",
    "  parser.add_argument('--epochs', default=300, type=int)\n",
    "  parser.add_argument('--device', default='cuda:0',\n",
    "                        help='device to use for training / testing')\n",
    "  parser.add_argument('--start_epoch', default=0, type=int, metavar='N',\n",
    "                        help='start epoch')\n",
    "  parser.add_argument('--resize', default=224, type=int)\n",
    "\n",
    "  # Model parameters\n",
    "  parser.add_argument(\"--input-size\", default=None, nargs=3, type=int, help='images input size')\n",
    "\n",
    "  # Optimizer parameters\n",
    "  parser.add_argument('--opt', default='adamw', type=str, metavar='OPTIMIZER',\n",
    "                      help='Optimizer (default: \"adamw\"')\n",
    "  parser.add_argument('--opt-eps', default=1e-8, type=float, metavar='EPSILON',\n",
    "                      help='Optimizer Epsilon (default: 1e-8)')\n",
    "  parser.add_argument('--opt-betas', default=None, type=float, nargs='+', metavar='BETA',\n",
    "                      help='Optimizer Betas (default: None, use opt default)')\n",
    "  parser.add_argument('--clip-grad', type=float, default=None, metavar='NORM',\n",
    "                      help='Clip gradient norm (default: None, no clipping)')\n",
    "  parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n",
    "                      help='SGD momentum (default: 0.9)')\n",
    "  parser.add_argument('--weight-decay', type=float, default=0.05,\n",
    "                      help='weight decay (default: 0.05)')\n",
    "\n",
    "  # Learning rate schedule parameters\n",
    "  parser.add_argument(\"--lr\", type=float, default=0.01, metavar=\"LR\")\n",
    "  \n",
    "  return parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args = get_args_parser().parse_args([\"--input-size\", \"3\", \"224\", \"224\"])\n",
    "args.epochs = 10\n",
    "args.resize = 224\n",
    "args.lr = 0.001\n",
    "Device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "EPOCHS = args.epochs\n",
    "BATCH_SIZE = args.batch_size\n",
    "RESEIZE = args.resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),  # 1チャンネルを3チャンネルに変換\n",
    "        transforms.Resize((RESEIZE, RESEIZE)),  # ViTモデルは大きな画像が必要\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "train_data_loader = get_mnist_dataset(train=True, transform=transform, batch_size=BATCH_SIZE)\n",
    "test_data_loader = get_mnist_dataset(train=False, transform=transform, batch_size=BATCH_SIZE)\n",
    "examples = next(iter(train_data_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_instance = ShowImages()\n",
    "\n",
    "show_images_instance.show_images_loader(dataset_lodaer=train_data_loader, num_images_to_display=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.swin_base_4_224(pretrained=True,  num_classes=10)\n",
    "model = models.swin_tiny_4_224(pretrained=True,  num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(args.device)\n",
    "train_loss_fn = nn.CrossEntropyLoss().cuda()\n",
    "validate_loss_fn = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "optimizer = create_optimizer(args, model)\n",
    "\n",
    "# Set up the learning rate scheduler (if needed)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_seconds(seconds):\n",
    "    minutes, seconds = divmod(seconds, 60)\n",
    "    hours, minutes = divmod(minutes, 60)\n",
    "    return hours, minutes, seconds\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, loss_fn, args):\n",
    "  batch_time_m = AverageMeter()\n",
    "  losses_m = AverageMeter()\n",
    "  accuracy_m = AverageMeter()\n",
    "\n",
    "  model.train()\n",
    "  start = time.time()\n",
    "  print(\"--Active train--\")\n",
    "  for _, (inputs, labels) in enumerate(loader):\n",
    "      # 勾配をゼロにリセット\n",
    "      optimizer.zero_grad()\n",
    "      # 入力データとラベルをデバイスに移動\n",
    "      inputs, labels = inputs.to(args.device), labels.to(args.device)\n",
    "      # モデルに入力データを渡して予測を取得\n",
    "      outputs = model(inputs)\n",
    "      # 損失を計算\n",
    "      loss = loss_fn(outputs, labels)\n",
    "      # 勾配を計算\n",
    "      loss.backward()\n",
    "      # オプティマイザでパラメータを更新\n",
    "      optimizer.step()\n",
    "\n",
    "      # 精度の計算\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      correct = (predicted == labels).sum().item()\n",
    "      accuracy = correct / labels.size(0)\n",
    "      accuracy_m.update(accuracy, labels.size(0))\n",
    "\n",
    "      # 更新\n",
    "      torch.cuda.synchronize()\n",
    "      losses_m.update(loss.item(), inputs.size(0))\n",
    "      batch_time_m.update(time.time() - start)\n",
    "      start = time.time()\n",
    "  train_accuracy = accuracy_m.avg * 100\n",
    "  # バッチごとの時間を表示\n",
    "  # バッチごとの時間を変換\n",
    "  batch_time_sum_h, batch_time_sum_min, batch_time_sum_sec = convert_seconds(batch_time_m.sum)\n",
    "  batch_time_avg_h, batch_time_avg_min, batch_time_avg_sec = convert_seconds(batch_time_m.avg)\n",
    "  print(\n",
    "      f\"Batch Time: {batch_time_sum_h:.0f}h {batch_time_sum_min:.0f}min {batch_time_sum_sec:.4f}sec, \"\n",
    "      f\"Batch Time Average: {batch_time_avg_h:.0f}h {batch_time_avg_min:.0f}min {batch_time_avg_sec:.4f}sec\"\n",
    "  )\n",
    "  print(f\"Accuracy: {train_accuracy:.2f}%, Loss: {losses_m.avg}\")\n",
    "  return {\n",
    "      'accuracy': train_accuracy,\n",
    "      'loss': losses_m.avg,\n",
    "      'batch_time_sum': batch_time_m.sum,\n",
    "      'batch_time_avg': batch_time_m.avg\n",
    "  }\n",
    "\n",
    "def test(model, loader, args):\n",
    "    print('--Active test--')\n",
    "    accuracy_m = AverageMeter()\n",
    "    # モデルを評価モードに設定\n",
    "    model.eval()\n",
    "    # 勾配を計算しないようにするための torch.no_grad() コンテキストを使用\n",
    "    with torch.no_grad():\n",
    "      # データローダーからバッチごとのデータを取得\n",
    "      for _, (inputs, labels) in enumerate(loader):\n",
    "        # 入力データとラベルをデバイスに移動\n",
    "        inputs, labels = inputs.to(args.device), labels.to(args.device)\n",
    "        # モデルに入力データを渡して予測を取得\n",
    "        output = model(inputs)\n",
    "        # 精度の計算\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        accuracy = correct / labels.size(0)\n",
    "        accuracy_m.update(accuracy, labels.size(0))\n",
    "    # テスト精度を計算\n",
    "    test_accuracy = accuracy_m.avg * 100\n",
    "    print(f\"Accuracy: {test_accuracy:.2f}%\")\n",
    "    return {'accuracy': test_accuracy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_history = []\n",
    "train_loss_history = []\n",
    "train_batch_time_history = []\n",
    "train_batch_time_ave_history = []\n",
    "test_accuracy_history = []\n",
    "\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    print(f\"Epoch [{epoch + 1}/{args.epochs}]\")\n",
    "    train_result = train_one_epoch(model, train_data_loader, optimizer, train_loss_fn, args)\n",
    "    test_result = test(model, test_data_loader, args)\n",
    "\n",
    "    # トレーニング結果を保存\n",
    "    train_accuracy_history.append(train_result['accuracy'])\n",
    "    train_loss_history.append(train_result['loss'])\n",
    "    train_batch_time_history.append(train_result['batch_time_sum'])\n",
    "    train_batch_time_ave_history.append(train_result['batch_time_avg'])\n",
    "\n",
    "    # テスト結果を保存\n",
    "    test_accuracy_history.append(test_result['accuracy'])\n",
    "\n",
    "final_save_path = path_functions_instance.absolutePath(SAVEWEIGHTPATH) \n",
    "torch.save(model.state_dict(), final_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グラフのx軸にエポック数を+1して1エポック目から始まるように修正\n",
    "x = list(range(1, args.epochs + 1))\n",
    "x_ticks = list(range(1, args.epochs + 1, 10))\n",
    "# グラフのプロット\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_accuracy_history, label=\"Train Accuracy\")\n",
    "plt.plot(test_accuracy_history, label=\"Test Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Training and Test Accuracy\")\n",
    "plt.yticks(range(0, 101, 10))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グラフのx軸にエポック数を+1して1エポック目から始まるように修正\n",
    "x = list(range(1, args.epochs + 1))\n",
    "x_ticks = list(range(1, args.epochs + 1, 10))\n",
    "# グラフのプロット\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss_history, label=\"Train Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Training Loss\")\n",
    "plt.yticks(range(0, 10, 1))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualization_instance = Visualization()\n",
    "chckpoint=SAVEWEIGHTPATH\n",
    "Visualization_instance.position_embedding(checkpointPath=chckpoint, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.visualization import Visualization\n",
    "import models\n",
    "\n",
    "Visualization_instance = Visualization()\n",
    "model = model = models.vit_tiny_16_224(pretrained=False, num_classes=10)\n",
    "checkpoint = SAVEWEIGHTPATH\n",
    "image_path = \"datasets/mnist/Image/sample_0.png\"\n",
    "\n",
    "Visualization_instance.attention_map(model=model, checkpointPath=checkpoint, imagePath=image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notificationInstants = Notification()\n",
    "customTimeInstants = Time()\n",
    "channel=\"vit-team\"\n",
    "message = (\n",
    "    f\"accuracy: {train_accuracy_history[-1]}%, loss: {train_loss_history[-1]}, accuracy: {test_accuracy_history[-1]}% \"\n",
    "    f\"Alltime: {customTimeInstants.convert_time_text(np.sum(train_batch_time_history))}, \"\n",
    "    f\"TimeAve: {customTimeInstants.convert_time_text(np.sum(train_batch_time_ave_history))}\"\n",
    ")\n",
    "notificationInstants.send_slack_notification(message=f\"SUCESS: Active {TITLE}\", channel=channel)\n",
    "notificationInstants.send_slack_notification(message=message, channel=channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
